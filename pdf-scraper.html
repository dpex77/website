<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>PDF Scraper Lab</title>
  <style>
    body {
      font-family: monospace, monospace;
      background: #fff;
      color: #000;
      margin: 40px;
      line-height: 1.5;
    }
    h1, h2, h3 {
      text-align: center;
      text-transform: uppercase;
    }
    pre {
      background: #f4f4f4;
      border: 1px solid #000;
      padding: 10px;
      overflow-x: auto;
    }
    code {
      font-family: monospace;
    }
    .section {
      margin-bottom: 40px;
    }
    .log {
      background: #eee;
      border-left: 4px solid #000;
      padding: 10px;
      margin: 10px 0;
    }
  </style>
</head>
<body>

<h1>PDF Scraper Proof-of-Concept Lab</h1>

<div class="section">
<h2>Readme</h2>
<p>
This lab demonstrates a simple PDF scraper written in Python.
It extracts text content from each page of a PDF using the <code>PyPDF2</code> library and saves it into a plain text file. 
For scanned/image-based PDFs, Optical Character Recognition (OCR) with <code>pytesseract</code> can be added as an extension.
</p>
</div>

<div class="section">
<h2>PDF Scraper Script (pdf_scraper.py)</h2>
<pre><code>import PyPDF2

def extract_text_from_pdf(pdf_path, output_txt="output.txt"):
    # Open the PDF file in read-binary mode
    with open(pdf_path, "rb") as file:
        reader = PyPDF2.PdfReader(file)
        text_content = []

        # Loop through all pages
        for page_num, page in enumerate(reader.pages, start=1):
            text = page.extract_text()
            if text:
                text_content.append(f"\\n--- Page {page_num} ---\\n{text}")
            else:
                text_content.append(f"\\n--- Page {page_num} ---\\n[No text extracted]")

    # Save extracted text to a file
    with open(output_txt, "w", encoding="utf-8") as out_file:
        out_file.write("\\n".join(text_content))

    print(f"[+] Extracted text saved to {output_txt}")

if __name__ == "__main__":
    # Change 'sample.pdf' to your PDF file path
    extract_text_from_pdf("sample.pdf", "scraped_output.txt")
</code></pre>
</div>

<div class="section">
<h2>Sample Output</h2>
<div class="log">
<pre><code>--- Page 1 ---
This is some text extracted from the first page.

--- Page 2 ---
Another page of text here...

--- Page 3 ---
[No text extracted]
</code></pre>
</div>
</div>

<div class="section">
<h2>Explanation</h2>
<p>
The script reads the PDF file using <code>PyPDF2.PdfReader</code> and iterates over each page.
It attempts to extract text and writes the result into a plain text file.
If a page contains no extractable text (common for scanned PDFs), a placeholder is recorded.
Adding OCR (with <code>pytesseract</code> and <code>pdf2image</code>) would allow handling scanned documents as well.
</p>
</div>

<div class="section">
<h2>Best Practices</h2>
<ul>
  <li>Always check whether your PDF contains selectable text or scanned images.</li>
  <li>Use OCR libraries such as <code>pytesseract</code> for image-based PDFs.</li>
  <li>Keep extracted text secured if the PDF contains sensitive information.</li>
  <li>Consider cleaning or normalizing the extracted text for downstream processing.</li>
</ul>
</div>

</body>
</html>
